{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021-2022 Digital Text Analysis | Bootcamp\n",
    "## August exam period\n",
    "\n",
    "Welcome to the practical exam. Below are a number of questions that test the skills you've learnt during the bootcamp.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "- You have **2 hours** to complete the exam.\n",
    "- This is an **open book exam**. You may use the web, course notes or any other resources to assist you. You may NOT get live assistance from third parties (incl. fellow students), e.g. by solving the exam together with others in a chat.\n",
    "\n",
    "\n",
    "Marking:\n",
    "- The exam consists of a total of 20 points.\n",
    "- Each exercise states how many points can be earned.\n",
    "- Each point represents a grade, e.g. if you achieve 18 points, your grade is an 18.\n",
    "- Points can be earned for **partial answers**, so fill in what you can. \n",
    "\n",
    "Tips:\n",
    "\n",
    "- This exam does not ask you to show skills that you have not learne during the bootcamp. Keep it simple, keep it familiar. \n",
    "- Use notes to plan your answers.\n",
    "- Use `print` statements to explore the data and debug your code.\n",
    "- Show us the steps of the process that you **do** understand, even if you can't complete the process fully.\n",
    "- In Python there is no `NoCodeError`, so don't stare at empty cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Friends (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we'll work with an open dataset [from Kaggle](https://www.kaggle.com/datasets/rezaghari/friends-series-dataset) on the popular sitcom [\"Friends\"](https://en.wikipedia.org/wiki/Friends) which aired from 1994 to 2004. Each row in this dataset describes data on a single episode (but note that some episodes, like season finales are listed more than once, because they consist of multiple parts that aired separately.)\n",
    "\n",
    "- Load the dataset (which you can find as `friends.csv`in the same folder as this notebook) using `pandas`.\n",
    "- Display the first 10 entries in the dataset.\n",
    "- Print how many episodes are included and find out how many seasons are included.\n",
    "- Consider the ratings (cf. `Stars` column):\n",
    "    + Rank the rows in the dataset according to their ratings in decreasing order: which is the most popular episode?\n",
    "    + Create a new series containing the mean rating per season.\n",
    "    + Rank (in increasing order) the resulting series of means and plot them using a bar chart.\n",
    "- Count how often each Director appears in the dataset and plot their cumulative frequency as a *horizontal* bar chart.\n",
    "- Iterate over the `Summary` column: write these summaries of each Friends episode away to a new plain text file (`summaries.txt`) and write away each summary to a separate line.  Make sure to write to the file in a safe way. Make sure that the summaries do not contain any linebreaks anymore before writing them away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Frequency distributions (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iterate over the summaries in `summaries.txt` in a line-by-line fashion and store them in a tuple. Make sure to read the file in a safe way.\n",
    "- Use `collections.Counter` to iterate over the summaries and count out which of the lead characters (see dictionary below, which includes gender information) is most frequently mentioned in the summaries.\n",
    "- Convert the resulting frequency distribution to a `pandas` object (use as column names `character` and `count`) and plot the result as a bar chart.\n",
    "- Consider character interaction: consider all pairs of characters and count (in a data structure of your own choice) how many episodes these characters co-occur. Which two characters are most frequently mentioned together in the summaries?\n",
    "- **Intermediate:** Consider the statistics that you collected in the previous question: try to write (preferably elegant) code to explicitly count how often the men interact with one another and how often the women interact with one another. Also calculate the mass of mixed-gender interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = {'Joey': 'M', 'Rachel': 'F', 'Monica': 'F', 'Phoebe': 'F', 'Chandler': 'M', 'Ross': 'M'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functions and regular expressions (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define a function that can sentence-tokenize an arbitrary string (an input parameter that you can call `text`) and returns the resulting sentences as a tuple. For this purpose, you should work with a regular expression that matches any series of the punctuation marks '.', '!', and '?' immediately followed by at least one instance of whitespace.\n",
    "- Add a boolean parameter `lowercase` to the function's signature which defaults to False and which will lowercase the resulting sentences when set to `True` and add the desired behaviour to the string.\n",
    "- The function should raise a `ValueError` if one of the two parameters (`text` and `lowercase`) does not have the expected type. Add an informative error message.\n",
    "- Use this naive sentence tokenizer to count how many sentences the summaries contain in total. (Assert that you have a higher sentence count than summary count, because summaries contain multiple sentences.)\n",
    "- **Advanced:** At the start of a sentence, all words are normally capitalized. In the summaries, we should be able to naively detect the names of other, non-lead characters, because their names will be capitalized, also when they occur in the middle of a sentence. Exploit this regularity and attempt to automatically detect the names of other characters. Count their occurences in the summaries to find out the most frequently occuring *side* characters (i.e. while ignoring lead character). *Hint: the most frequently mentioned side character appears to be \"Emily\"*.\n",
    "    + Remove genitival endings (e.g. `Paolo's`)\n",
    "    + Also, strings that are all caps (e.g. 'TV') should be disregarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A search engine (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a (modest) search engine for our Friends dataset:\n",
    "1. Invite the user of this notebook to insert a query string using `input()`. Use whitespace to split multiple query terms as a simple tokenization strategy.\n",
    "2. Retrieve all episodes from the data set in which one of the search terms is present in the summary column or the title column.\n",
    "3. Improve your search engine: episodes in which we find more matches of the query terms should be ranked higher in the result.\n",
    "4. A search command might not yield any results: make sure that your code keeps on asking the user for a new query string using a `while` loop.\n",
    "5. **Advanced**: If the query did not yield any results, suggest to the user an alternative query that is somehow similar to the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
