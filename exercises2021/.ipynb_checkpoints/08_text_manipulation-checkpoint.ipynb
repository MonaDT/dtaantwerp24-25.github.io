{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises on String Manipulation\n",
    "\n",
    "Use this [notebook](https://github.com/dtaantwerp/dtaantwerp.github.io/blob/master/notebooks2021/12_Week2_Wednesday_string_text_manipulation.ipynb) for a complete explanation of String Manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Implement an echo function that repeats text by n times\n",
    "\n",
    "Input parameters: 1. text: str, 2. times: int  \n",
    "Output parameters: 3. text: str\n",
    "\n",
    "Format output text in such a way that given text always starts from a new line.  \n",
    "\n",
    "To-do:\n",
    "1. Define an Echo function with given input and output parameters;\n",
    "2. Concatenate new line character (`\\n`) to input text;\n",
    "3. Multiply modified text by a given number of times;  \n",
    " \n",
    "\n",
    "4. Print output of echo function for a given 'text' and 'times' variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Falling In Love Again with Python!'\n",
    "times = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = echo(text, times)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2a. Upgrade the echo function that reduces the number of characters in text after each repetition\n",
    "\n",
    "Input parameters: 1. text: str, 2. times: int, 3. reduction_rate: float   \n",
    "Output parameters: 3. text: str\n",
    "\n",
    "Format output text in such a way that given text always starts from a new line.  \n",
    "\n",
    "To-do:\n",
    "1. Modify function definition to take as input new parameter;\n",
    "2. Initialize 'new_text' variable that will accumulate reduced texts;\n",
    "3. Implement 'for loop' to iterate over the number of repetitions;\n",
    "4. Calculate the length of text after each reduction (e.g. text lenght=100, reduction_rate=0.7, new length after reduction = 70 (100*0.7);\n",
    "5. Cast calculated length to an integer;\n",
    "6. Reduce the number of characters to a given length;  \n",
    "7. Add reduced text with a new line character to the variable that accumulates reduced texts; \n",
    "\n",
    "\n",
    "8. Print output of echo function for a given 'text', 'times', 'reduction_rate' variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Falling In Love Again with Python!'\n",
    "times = 10\n",
    "reduction_rate = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = echo(text, times, reduction_rate)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2b. Upgrade echo function from 2a, so it outputs full text first and then reduces text after each repetition\n",
    "\n",
    "Input parameters: 1. text: str, 2. times: int, 3. reduction_rate: float   \n",
    "Output parameters: 3. text: str\n",
    "\n",
    "Format output text in such a way that given text always starts from a new line.  \n",
    "\n",
    "To-do:\n",
    "1. Implement if-else logic to skip text reduction during the first iteration.  \n",
    " \n",
    "\n",
    "2. Print output of echo function for a given 'text', 'times', 'reduction_rate' variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Falling In Love Again with Python!'\n",
    "times = 10\n",
    "reduction_rate = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = echo(text, times, reduction_rate)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3a. Implement basic version of Naive Named-entity Recognizer\n",
    "\n",
    "Input parameters: 1. texts: list  \n",
    "Output parameters: 2. entities: list \n",
    "\n",
    "To-do:  \n",
    "1.1. Define helper function 'cap_word_extractor' that takes a text and returns a list of capitalized words;  \n",
    "1.2. Initialize cap_words variable to accumulate capitalized words;   \n",
    "1.3. Break text into chunks separating it by whitespace character;  \n",
    "1.4. Iterate over tokens to identify tokens that are not lowercased;  \n",
    "1.5. Add selected tokens to cap_words variable;  \n",
    "\n",
    "2.1. Define a ner function with given input and output parameters;  \n",
    "2.2. Initialize 'entities' variable to accumulate entities;   \n",
    "2.3. Iterate of over given texts;  \n",
    "2.4. Apply cap_word_extractor to each text;  \n",
    "2.4. Add entities to entities variable;   \n",
    "\n",
    "3.1. Execute ner function for given input;  \n",
    "3.2. Print entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"Apparently while learning English, GPT-2 also accidentally picked up some JavaScript\",\n",
    "         \"I don't think anyone's really concerned about GPT-2 pioneering a new form of hate speech...but customized hate speech of infinite length, diversity for getting through bot filters/human detection of it being from 1 source?\",\n",
    "         \"This debate isn't *just* about GPT-2 and how risky it is today, but how to proceed given real tradeoffs (e.g. between showing people what the risks are by letting them use it, vs. limiting misuse), and we should have that convo before the next phase of LMs are widely deployed.\",\n",
    "         \"Fears of OpenAI's super-trolling artificial intelligence are overblown\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for 1.1 - 1.5 here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for 2.1 - 2.4 here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for 3 here:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3b. Upgrade the basic version of Naive Named-entity Recognizer by filtering out punctuation, stopwords, and the first word in texts.\n",
    "\n",
    "Input parameters: 1. texts: list, punctuation: str, stopwords: list\n",
    "Output parameters: 2. entities: dict\n",
    "        \n",
    "Instead of returning a raw list of entities, return a count of unique entities. \n",
    "\n",
    "To-do:  \n",
    "1.1. Define 'clean_text' function that takes in text, punctuation, and stopwords parameters. Function filters punctuation and stopwords from a text. It returns a list of tokens;    \n",
    "1.2. Iterate over punctuation and remove it from a text;  \n",
    "1.3. Break text into chunks separating it by whitespace character;  \n",
    "1.4. Iterate over tokens. Skip first token (i.e., make a naive assumption that Named Entities are not among first words). Filter out tokens that belong to stopwords (lowercase tokes);  \n",
    "\n",
    "2.1. Modify cap_word_extractor function to take as input list of tokens;  \n",
    "2.2. Exclude tokens that are digits;  \n",
    "\n",
    "3.1. Modify ner function to clean text from punctuation and stopwords;  \n",
    "3.2. Calculate the frequency of each entity;\n",
    "\n",
    "4.1. Execute ner function for a given input;  \n",
    "4.2. Print quantities sorted from larger to smaller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = '''!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for 1:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for 2:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for 3:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for 4:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Decipherment of secret script.\n",
    "\n",
    "You received an encoded message and keys (cipher: Python dictionary). Accidentally, the keys in the cipher were shifted, but the order is still correct. Implement a function that finds the right combination of keys to encode given text. You received the hint that the text contains a specific work (see hint).\n",
    "\n",
    "Implement a function that finds the correct combination of keys and decodes the text.\n",
    "\n",
    "Input parameters: 1. encoded_text: string, broken_codes: dict, hint: str  \n",
    "Output parameters: 2. decoded_text: str\n",
    "        \n",
    "\n",
    "To-do:  \n",
    "Implement the helper function 'convert_text' that converts a text based on the cipher.  \n",
    "\n",
    "1.1. Define function 'convert_text' that as input takes text: str and codes: dict and returns decoded text;  \n",
    "1.2. Convert string to list of characters;  \n",
    "1.3. Iterate over characters and change characters to the corresponding character in codes (e.g., code {'X':'z'}, so X-->z);    \n",
    "1.4. Convert a decoded list of characters to a string.     \n",
    "\n",
    "Implement the 'crack_code' function that finds the correct codes.  \n",
    "\n",
    "2.1. Define 'crack_code' function that takes encoded_text: string, broken_codes: dict, hint: str and returns decoded_text: str;  \n",
    "2.2. Obtain a list of alphabetic characters from wrong codes;    \n",
    "2.3. Obtain a list of corresponding codes from wrong codes;    \n",
    "2.4. In a loop, shift codes by one element. Use combination of append() and pop() methods;  \n",
    "2.5. Construct a new cipher based on shifted codes;  \n",
    "2.6. Decode text with new cipher;  \n",
    "2.7. Check whether hint word is in the converted text;  \n",
    "2.8. Stop iterating when the correct cipher is found;  \n",
    "2.9. Return decoded text;  \n",
    "2.10. Print decoded text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = 'dunSSBmS ueFS PLPCm, PLPCm uBcCmS mBuo, mBuo umeSOCS knRLmI, knRLmI PBnSBtS dPBuo, dPBuo SWLSOCS SunSSBmS, SunSSBmS ICuLPnFLFCS knRLmI, knRLmI CLFS PLPCm, PLPCm InSPmBcCS dPBuo, dPBuo cLPBmnRCS mBuo, LtI LS nF LkELTS OLS, mBuo umeSOCS SunSSBmS.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_codes = {'A': 'A', 'Q': 'B', 'J': 'C', 'd': 'D', 'X': 'E', 'j': 'F', 'G': 'G', 'g': 'H', 'M': 'I', 'q': 'J',\n",
    "                'y': 'K', 'L': 'L', 'H': 'M', 'u': 'N', 'I': 'O', 'C': 'P', 'U': 'Q', 'D': 'R', 'O': 'S', 'n': 'T',\n",
    "                'i': 'U', 'o': 'V', 'k': 'W', 'W': 'X', 't': 'Y', 'B': 'Z', 'P': 'a', 'r': 'b', 'm': 'c', 'S': 'd',\n",
    "                'F': 'e', 'e': 'f', 'c': 'g', 'E': 'h', 'f': 'i', 'T': 'j', 'R': 'k', 'z': 'l', 'b': 'm', 'V': 'n',\n",
    "                'x': 'o', 's': 'p', 'l': 'q', 'h': 'r', 'N': 's', 'p': 't', 'v': 'u', 'Z': 'v', 'Y': 'w', 'w': 'x',\n",
    "                'a': 'y', 'K': 'z'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = 'Spock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for 1.1 - 1.4 here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for 2.1 - 2.9 here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = crack_code(encoded_text, broken_codes, hint)\n",
    "print(decoded_text)  # this is 2.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Simple semantic Triples extractor\n",
    "\n",
    "Implement a function that extracts semantic triples (Subject, Predicate, Object) from text based on some heuristics.\n",
    "\n",
    "Input parameters: 1. text: str  \n",
    "Output parameters: 2. triples: list\n",
    "        \n",
    "\n",
    "To-do:  \n",
    "Implement the helper function 'clean_text' that lowercases text and removes punctuation.   \n",
    "\n",
    "1.1. Define function 'clean_text' that as input takes text: str and punctuation: str and returns cleaned text;    \n",
    "1.2. Iterate over punctuation and remove it from a text;  \n",
    "1.3. Lowercase text;     \n",
    "\n",
    "Implement an 'extract_triples' function that extracts semantic triples.   \n",
    "\n",
    "2.1. Define 'extract_triples' function that takes text: str and returns triples: list;   \n",
    "2.2. Divide  text based on 'comma' character;     \n",
    "2.3. Remove extra white spaces from obtained chunks of text;  \n",
    "2.4. Divide chunks based on 'whitespace' character;  \n",
    "2.5. Filter chunks that have three elements (triples);  \n",
    "2.6. Clean each element of triple applying the 'clean_text' function;  \n",
    "2.7. Return list of triples;  \n",
    "\n",
    "Implement an 'extract_spo' function that creates lists of unique subjects, predicates, and objects.\n",
    "\n",
    "3.1. Define 'extract_spo' function that takes triples: list and returns subjects: list, objects: list, predicates: list;  \n",
    "3.2. Initiate subjects, objects, predicates sets;  \n",
    "3.3. Iterate over a list of triples;  \n",
    "3.4. Add corresponding elements of triples to sets of subjects, predicates, and objects;  \n",
    "3.5. Sort list of subjects, predicates, and objects;  \n",
    "3.6. Return lists of subjects, predicates, and objects;  \n",
    "3.7. Print lists of subjects, predicates, and objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for 1 here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for 2 here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for 3 here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = extract_triples(decoded_text)\n",
    "print(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects, predicates, objects = extract_spo(triples)\n",
    "print(subjects, predicates, objects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
